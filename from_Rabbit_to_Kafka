####################################ячейка в Google Colab №1 - установка и импорт библиотек###########################################
#установка библиотек
!pip install pika
!pip install kafka-python 

#импорт модулей 
import pika
import json
import random
import time
from time import sleep
from kafka import KafkaProducer

####################################ячейка в Google Colab №2 - потребление из RabbitMQ и публикация сообщений в Kafka###########################################
# объявление продюсера Kafka
producer = KafkaProducer(
  bootstrap_servers=['........здесь взять название своего сервера.upstash.io:9092'],
  sasl_mechanism='SCRAM-SHA-256',
  security_protocol='SASL_SSL',
  sasl_plain_username='.........здесь имя пользователя, взятое из upstash',
  sasl_plain_password='..........здесь пароль для этого пользователя',
  value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

# Подключение к серверу RabbitMQ server в облачной платформе cloudamqp.com 
connection = pika.BlockingConnection(pika.URLParameters('.........здесь взять адрес подключения к своему инстансу в https://customer.cloudamqp.com/instance'))
channel = connection.channel()

#объявление обменника RQM, заранее созданного в cloudamqp.com
channel.exchange_declare(exchange='InputsFanoutExchange', exchange_type='fanout')

#объявление очереди RQM
inputs_queue = channel.queue_declare(queue='InputsQueue')

#бесконечный цикл потребления и публикации
while True: 
  #определяем функцию обратного вызова для потребления сообщений из очереди RQM
  def on_inputs_message(ch, method, properties, body):
   #обработка полезной нагрузки в JSON 
   dictData = json.loads(body)
   print("Входящее обращение от ", dictData['id'], "клиент ", dictData['name'], "тема ", dictData['subject'], "содержание ", dictData['content'])

   id=dictData['id']
   name=dictData['name']
   subject = dictData['subject']
   content = dictData['content']

   #задаем ключ партиционирования для Kafka
   mes_key = str.encode(subject+name)

   #создаем полезную нагрузку в JSON 
   data = {'id': id, 'name': name, 'subject': subject, 'content': content}

   #публикуем данные в Kafka
   future = producer.send('InputsTopic', value=data, key=mes_key)
   record_metadata = future.get(timeout=60)
   print(f' [x] Sent {record_metadata}')
  
  #потребляем данные из RabbitMQ
  print('Waiting for messages. To exit press CTRL+C')
  channel.basic_consume(queue=inputs_queue.method.queue, on_message_callback=on_inputs_message, auto_ack=True)
  channel.start_consuming()
  
####################################ячейка в Google Colab №3 - закрытие соединения###########################################
#Закрываем соединения
channel.close()
connection.close()
producer.close()
